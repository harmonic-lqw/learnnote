# 复杂度分析（上）

+ 所有代码的执行时间T(n)与每行代码的执行次数f(n)成正比：`T(n)=O(f(n))`
  + T(n)表示代码执行的时间
  + n表示数据规模的大小
  + f(n)表示每行代码执行的次数总和
  + 当n很大时，我们只需要记录一个最大量级就可以了，即`T(n) = O(2n2+2n+3)`记成`T(n) = O(n2)`
+ 大O时间复杂度表示法并不具体表示代码的真正执行时间，而是表示代码执行时间随数据规模增长的变化趋势，也叫渐进时间复杂度，简称时间复杂度
+ 渐进时间复杂度：表示算法的执行时间与数据规模之间的增长关系

## 三种常用分析方法

1. 只关注执行次数最多的一段代码：我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度：
   + 注意：如果某段代码循环了已知的次数，哪怕次数很大，但是对时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间按多大，在分析时间复杂度时，都可以忽略掉
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

## 常见复杂度量级：

![常见复杂度量级](D:\note_file\王争数据结构与算法\常见复杂度量级.jpg)

## 多项式时间复杂度：

+ O(1)：一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)
+ O(logn)、O(nlogn)：

![对数阶时间复杂度分析](D:\note_file\王争数据结构与算法\对数阶时间复杂度分析.jpg)

+ O(m+n)、O(m*n)：表示代码的复杂度由两个数据的规模来决定

## 空间复杂度分析：

+ 空间时间复杂度全称是渐进空间复杂度：表示算法的存储空间与数据规模之间的增长关系
+ 常见的有O(1)、O(n)、O(n**2)，分析方法类似时间复杂度分析

# 复杂度分析（下）

## 最好情况时间复杂度：

+ 在最理想的情况下，执行这段代码的时间复杂度

## 最坏情况时间复杂度：

+ 在最糟糕的情况下，执行这段代码的时间复杂度

## 平均情况时间复杂度：

+ 平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度

**很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分**

## 均摊时间复杂度：

+ 均摊时间复杂度就是一种特殊的平均时间复杂度
+ 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。**而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度**

# 数组

## 什么是数组：

+ 数组是一种**线性表**数据结构。他用一组连续的内存空间来存储一组具有相同数据类型的数据
+ 线性表：数据排成像一条线一样的结构
+ 非线性表：类似二叉树、堆、图，数据之间不是简单前后关系
+ 数组支持随机访问，根据下标随机访问的时间复杂度为O(1)
+ 数组插入、删除操作的平均时间复杂度为O(n)，最好都是O(1)，最坏都是O(n)

## 数组越界：

+ 在C语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的
+ 访问数组的本质就是访问一段连续的内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误
+ ArrayList和C++STL中的vector是针对数组类型提供的容器类，这些类将数组操作的细节封装起来，而且支持动态扩容，每次存储空间不够的时候，ArrayList会将空间自动扩容为1.5倍大小

# 链表（上）

+ 缓存淘汰策略常见的有三种：先进先出策略FIFO、最少使用策略LFU、最近最少使用策略LRU
+ 链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的“结点”，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址，录下个结点地址的指针叫作后继指针 next
+ 链表常见的有单链表、循环链表、双向链表
+ 数组更适合CPU的缓存机制，而链表在内存中不是连续存储的，对CPU缓存不友好，没有办法有效预读。CPU缓存：CPU缓存存在的意义:为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入，CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。而CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块，并保存到CPU缓存中，然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制

# 链表（下）

+ 针对链表的插入、删除操作，需要对插入的第一个节点和删除的最后一个节点进行特殊处理
+ 哨兵节点：有哨兵节点的链表叫带头链表，没有的叫不带头链表
+ 哨兵结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑![带头链表](D:\note_file\王争数据结构与算法\带头链表.jpg)
+ 写链表代码的六个技巧：理解指针或引用的含义、警惕指针丢失和内存泄漏、利用哨兵简化实现难度、重点留意边界条件处理，以及举例画图、辅助思考，还有多写多练
+ 链表代码的几个常见题：单链表反转、链表中环的检测、两个有序链表的合并、删除链表倒数第n个结点、求链表的中间结点。练习题LeetCode对应编号：206，141，21，19，876

# 跳表

## 什么是跳表：

+ 链表添加多级索引的结构
+ 添加索引的方式：每几个结点提取一个结点到上一级，我们把抽出来的那一级叫做索引或索引层
+ 每加一层索引，查找的一个结点需要遍历的结点个数减少了，也就是效率提高了
+ **支持查找、动态插入、删除**，而且插入和删除的时间复杂度也是O(logn)，跟查找一样
+ 可以通过改变索引构建策略，有效平衡执行效率和内存消耗

## 时间复杂度：

+ O(logn)
+ 与二分查找的时间复杂度一样，也就是说我们是基于单链表实现了二分查找

## 空间复杂度：

+ 虽然每两个结点进行提取和每三个结点进行提取，空间复杂度理论上都是O(n)，但是后者要比前者使用的额外的索引结点数少一半

# 散列表(哈希表、Hash表)

## 什么是散列表：

+ 散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来

## 散列函数：

+ 可以定义成hash(key)，其中key表示元素的键值，value值就是散列表要存储的值，但hash(key)的值表示经过散列函数计算得到的散列值
+ 值是value，对应的键是key，把key带入到散列函数中，通过散列函数计算得到的**散列值**是**存储value的数组的下标值**，不是value

### 散列函数设计的三点基本要求

1. 散列函数计算得到的散列值是一个非负整数
2. 如果key1 = key2，那hash(key1) == hash(key2)
3. 如果key1 != key2，那hash(key1) != hash(key2)

## 解决散列冲突的常用方法：

### 开放寻址法：

+ 核心思想：如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入，探测方法常用的有
  + 线性探测
  + 二次探测
  + 双重散列
+ 装载因子：表示散列表中空位的多少。计算公式：`散列表的装载因子 = 填入表中的元素个数/散列表的长度`，装在因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降
+ 当**数据量比较小**、**装载因子小**的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因

### 动态扩容：

+ 为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程

### 链表法：

+ 核心思想：在散列表中，每个“桶”或者“槽”会对应一条链表，所有散列值相同的元素我们都放在相同槽位对应的链表中
+ 当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。当查找、删除一个元素时，我们同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除
+ 对大装载因子的容忍度更高
+ 基于链表的散列冲突处理方法比较适合**存储大对象**、**大数据量**的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表

## 如何设计散列函数

+ 不能太复杂：复杂了影响计算时间
+ 散列函数的生成值要尽可能的随机且均匀分布
+ 设计方法：直接寻址、平方取中、折叠、随机数

## 装载因子过大：

+ 装载因子越大表示散列表中的元素越多，空闲位置越少，散列冲突的概率越大
+ 可以通过动态的扩容，当装载因子过高时，重新申请内存空间，重新计算哈希位置，并搬移数据

+ 装载因子阈值的设置要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1

## 工业级散列表要求：

+ 支持快速地查询、插入、删除操作
+ 内存占用合理，不能浪费过多的内存空间
+ 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况

## 散列函数设计思路：

+ 设计一个合适的散列函数
+ 定义装载因子阈值，并且设计动态扩容策略
+ 选择合适的散列冲突解决方法

# 递归

## 递归需要满足的三个条件：

1. **一个问题的解可以分为几个子问题的解**，所谓子问题，是指数据规模更小的问题
2. **这个问题与分解后的子问题，除了数据规模不同，求解思路完全一样**
3. **存在递归终止条件**

## 如何编写递归代码：

1. **写出递推公式**：将问题分成仅数据规模不同的子问题
2. **找到终止条件**：找到符合逻辑的正常终止条件

+ **写递归代码的关键**：找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码

## 如何更好的理解递归：

+ 如果一个问题 A 可以分解为若干子问题 B、C、D，你可以假设子问题 B、C、D 已经解决，在此基础上思考如何解决问题 A。而且，你只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了
+ **编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤**

## 递归代码要避免堆栈溢出：

+ **堆栈溢出**：函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。
+ 可以通过在代码中限制递归调用的最大深度的方式来解决堆栈溢出

## 递归代码要警惕重复计算：

+ 可以用散列表这种数据结构来解决

# 排序（上）

## 如何分析排序算法的执行效率：

1. 分析最好情况、最坏情况、平均情况时间复杂度。因为对于有序度不同的数据，对于排序的执行时间肯定是有影响的
2. 时间复杂度的系数、常数、低阶。我们排序的数据规模可能很小，所以要把这些也考虑进来
3. 比较次数和交换次数。特别是对于基于比较的排序算法，会涉及到元素的大小的比较和元素的移动。
4. 排序算法的内存消耗。**原地排序**：特指空间复杂度是O(1)的排序算法
5. 排序算法的稳定性。**稳定性**：是说如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。根据这个概念可以将排序算法分为**稳定的排序算法**和**不稳定的排序算法**

## 冒泡排序：

### 例代码：

```c++

// 冒泡排序，a表示数组，n表示数组大小
public void bubbleSort(int[] a, int n) {
  if (n <= 1) return;
 
 for (int i = 0; i < n; ++i) {
    // 提前退出冒泡循环的标志位
    boolean flag = false;
    for (int j = 0; j < n - i - 1; ++j) {
      if (a[j] > a[j+1]) { // 交换
        int tmp = a[j];
        a[j] = a[j+1];
        a[j+1] = tmp;
        flag = true;  // 表示有数据交换      
      }
    }
    if (!flag) break;  // 没有数据交换，提前退出 这里保证了最好的时间复杂度为O(1)
  }
}
```

### 时间复杂度：

+ 最好：O(n)，最坏情况O(n**2)。因为一次冒泡，时间复杂度是O(n)，而最好情况下冒泡一次即可，最坏情况下要冒泡n次

+ 平均时间复杂度O(n\**2)：这里有几个概念。**有序度**：数组中具有有序关系的元素对的个数。**对于一个完全有序的数组，有序度为**

  **nX(n-1)/2**，我们把这种**完全有序的数组的有序度叫做满有序度**。**逆序度=满有序度-有序度**。排序的过程就是增加有序度，减少逆序度的过程。所以，最坏情况下需要nX(n-1)/2交换，最好情况下需要0次交换，所以平均需要nX(n-1)/4交换。而比较操作比交换操作多，而复杂度上限时O(n\**2)，所以平均情况下的时间复杂度时O(n**2).

### 是原地排序：

+ 冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为 O(1)，是一个原地排序算法

### 是稳定的排序：

+ 为了保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，我们不做交换，相同大小的数据在排序前后不会改变顺序，所以冒泡排序是稳定的排序算法

## 插入排序：

### 例代码：

```c++

// 插入排序，a表示数组，n表示数组大小
public void insertionSort(int[] a, int n) {
  if (n <= 1) return;

  for (int i = 1; i < n; ++i) {
    int value = a[i];
    int j = i - 1;
    // 查找插入的位置
    for (; j >= 0; --j) {
      if (a[j] > value) {    // 这里没有写大于等于，保证了排序算法的稳定性
        a[j+1] = a[j];  // 数据移动
      } else {
        break;
      }
    }
    a[j+1] = value; // 插入数据
  }
}
```

+ 首先，我们将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束

### 时间复杂度：

+ 最好：O(n)
+ 最坏：O(n**2)，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据
+ 平均：O(n**2)，在数组中插入一个数据的平均时间复杂度是O(n)，所以对于插入排序来说，每次插入操作相当于在数组中插入一个数据，循环执行n次插入操作

### 是原地排序：

+ 插入排序算法运行不需要额外的存储空间，所以空间复杂度为O(1)

### 是稳定的排序：

+ 对于相同的元素，我们选择将后面插入的元素，插入到前面出现的元素的后面，便可以实现原有的相同的数据前后顺序不变

## 选择排序：

### 过程：

+ ![选择排序原理图](D:\note_file\王争数据结构与算法\选择排序原理图.jpg)

+ 选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾

### 时间复杂度：

+ 最好、最坏、平均都是O(n**2)

### 是原地排序

### 不是稳定排序

# 排序（下）

## 归并排序：

### 原理：

+ 如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。
+ ![归并排序分解图](D:\note_file\王争数据结构与算法\归并排序分解图.jpg)

### 伪代码：

```c

// 归并排序算法, A是数组，n表示数组大小
merge_sort(A, n) {
  merge_sort_c(A, 0, n-1)
}

// 递归调用函数
merge_sort_c(A, p, r) {
  // 递归终止条件
  if p >= r  then return

  // 取p到r之间的中间位置q
  q = (p+r) / 2
  // 分治递归
  merge_sort_c(A, p, q)
  merge_sort_c(A, q+1, r)
  // 将A[p...q]和A[q+1...r]合并为A[p...r]
  merge(A[p...r], A[p...q], A[q+1...r])
}


merge(A[p...r], A[p...q], A[q+1...r]) {
  var i := p，j := q+1，k := 0 // 初始化变量i, j, k
  var tmp := new array[0...r-p] // 申请一个大小跟A[p...r]一样的临时数组
  while i<=q AND j<=r do {
    if A[i] <= A[j] {
      tmp[k++] = A[i++] // i++等于i:=i+1
    } else {
      tmp[k++] = A[j++]
    }
  }
  
  // 判断哪个子数组中有剩余的数据
  var start := i，end := q
  if j<=r then start := j, end:=r
  
  // 将剩余的数据拷贝到临时数组tmp
  while start <= end do {
    tmp[k++] = A[start++]
  }
  
  // 将tmp中的数组拷贝回A[p...r]
  for i:=0 to r-p do {
    A[p+i] = tmp[i]
  }
}
```

### 是稳定的排序：

+ 在合并的过程中，如果 A[p...q]和 A[q+1...r]之间有值相同的元素，那我们可以像伪代码中那样，先把 A[p...q]中的元素放入 tmp 数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。

### 时间复杂度：

+ 最好、最坏、平均都是O(nlogn)

### 不是原地排序：

+ 是O(n)：递归代码的空间复杂度并不能像时间复杂度那样累加。尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)。

## 快速排序：

### 原理：

+ 快排的思想是这样的：如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。
+ ![快速排序](D:\note_file\王争数据结构与算法\快速排序.jpg)

### 伪代码：

```c

// 快速排序，A是数组，n表示数组的大小
quick_sort(A, n) {
  quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r为下标
quick_sort_c(A, p, r) {
  if p >= r then return
  
  q = partition(A, p, r) // 获取分区点
  quick_sort_c(A, p, q-1)
  quick_sort_c(A, q+1, r)
}


partition(A, p, r) {
  pivot := A[r]
  i := p
  for j := p to r-1 do {  // 这样i左边的始终小于pivot
    if A[j] < pivot {
      swap A[i] with A[j]
      i := i+1
    }
  }
  swap A[i] with A[r]
  return i

```

### 是原地排序：

+ ![原地partition操作图解](D:\note_file\王争数据结构与算法\原地partition操作图解.jpg)

### 不是稳定排序：

+ 因为涉及到交换

### 时间复杂度：

+ 最坏的情况下是O(n\**2)，平均情况下是O(nlogn)，但是快排退化到O(n**2)的概率非常小，可以通过合理地选择pivot来避免这种情况

# 二叉树

## 高度、深度、层的概念：

+ 高度：从下往上进行计数，计数起点是0
+ 深度：从上往下进行计数，计数起点是0
+ 层：从上往下进行计数，计数起点是1
+ ![高度深度层](D:\note_file\王争数据结构与算法\高度深度层.jpg)

## 链式存储法：

+ 每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针
+ 大部分二叉树都是通过链式存储结构来实现的

## 以数组的形式进行存储:

+ 如果节点X存储在数组中下标为i的位置，下标为2*i的位置存储的就是左子节点，下标为2\*i+1的就是右子节点。（为了方便计算，通常根节点会存储在下标为1的位置）
+ 针对完全二叉树通常采用这种结构，因为就不用像链式存储法那样，要存储额外的左右子节点的指针
+ 如果不是完全二叉树的话，用数组进行存储可能会造成空间上的浪费
+ **堆其实就是一种完全二叉树，最常用的存储方式就是数组**

## 前、中、后序遍历：

+ ```java
  
  void preOrder(Node* root) {
    if (root == null) return;
    print root // 此处为伪代码，表示打印root节点
    preOrder(root->left);
    preOrder(root->right);
  }
  
  void inOrder(Node* root) {
    if (root == null) return;
    inOrder(root->left);
    print root // 此处为伪代码，表示打印root节点
    inOrder(root->right);
  }
  
  void postOrder(Node* root) {
    if (root == null) return;
    postOrder(root->left);
    postOrder(root->right);
    print root // 此处为伪代码，表示打印root节点
  }
  ```

+ 每个节点最多会被访问两次，所以遍历操作的时间复杂度跟节点的个数n成正比，时间复杂度是O(n)

# 二叉查找树

## 定义：

+ 在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值

## 二叉查找树的搜索：

+ ```java
  public class BinarySearchTree {
    private Node tree;
  
    public Node find(int data) {
      Node p = tree;
      while (p != null) {
        if (data < p.data) p = p.left;
        else if (data > p.data) p = p.right;
        else return p;
      }
      return null;
    }
  
    public static class Node {
      private int data;
      private Node left;
      private Node right;
  
      public Node(int data) {
        this.data = data;
      }
    }
  }
  ```

## 二叉查找树的插入：

+ ```java
  public void insert(int data) {
    if (tree == null) {
      tree = new Node(data);
      return;
    }
  
    Node p = tree;
    while (p != null) {
      if (data > p.data) {
        if (p.right == null) {
          p.right = new Node(data);
          return;
        }
        p = p.right;
      } else { // data < p.data
        if (p.left == null) {
          p.left = new Node(data);
          return;
        }
        p = p.left;
      }
    }
  }
  ```

## 二叉查找树的删除：

+ ```java
  public void delete(int data) {
    Node p = tree; // p指向要删除的节点，初始化指向根节点
    Node pp = null; // pp记录的是p的父节点
    while (p != null && p.data != data) {
      pp = p;
      if (data > p.data) p = p.right;
      else p = p.left;
    }
    if (p == null) return; // 没有找到
  
    // 要删除的节点有两个子节点
    if (p.left != null && p.right != null) { // 查找右子树中最小节点
      Node minP = p.right;
      Node minPP = p; // minPP表示minP的父节点
      while (minP.left != null) {
        minPP = minP;
        minP = minP.left;
      }
      p.data = minP.data; // 将minP的数据替换到p中
      p = minP; // 下面就变成了删除minP了
      pp = minPP;
    }
  
    // 删除节点是叶子节点或者仅有一个子节点
    Node child; // p的子节点
    if (p.left != null) child = p.left;
    else if (p.right != null) child = p.right;
    else child = null;
  
    if (pp == null) tree = child; // 删除的是根节点
    else if (pp.left == p) pp.left = child;
    else pp.right = child;
  }
  ```

## 特性：

+ 中序遍历二叉查找树，可以输出有序的数据序列，**时间复杂度是 O(n)**，非常高效。因此，二叉查找树也叫作二叉排序树。
+ 完全二叉树的层数小于等于log2n + 1

# 递归树

+ 常用于分析复杂的时间复杂度，而时间复杂度的分析，思路很重要，不要纠结精确的时间复杂度到底是多少

# 二分查找

## 查找思想：

+ 针对一组有序的数据集合，有点类似分治思想，每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为0

## 时间复杂度：

+ O(logn)

## 简单代码：

+ 迭代实现

+ ```java
  public int bsearch(int[] a, int n, int value) {
    int low = 0;
    int high = n - 1;
  
    while (low <= high) {
      int mid = (low + high) / 2;
      if (a[mid] == value) {
        return mid;
      } else if (a[mid] < value) {
        low = mid + 1;
      } else {
        high = mid - 1;
      }
    }
    return -1;
  }
  ```
  
+ 递归实现

+ ```java
  public int bsearch(int[] a, int n, int val) {
    return bsearchInternally(a, 0, n - 1, val);
  }
  
  private int bsearchInternally(int[] a, int low, int high, int value) {
    if (low > high) return -1;
  
    int mid =  low + ((high - low) >> 1);
    if (a[mid] == value) {
      return mid;
    } else if (a[mid] < value) {
      return bsearchInternally(a, mid+1, high, value);
    } else {
      return bsearchInternally(a, low, mid-1, value);
    }
  }
  ```
  
+ **优化**：除二操作可以写成：`low + ((high - low)>>1)`

## 局限性：

+ 用于数组
+ 针对有序数据
+ 用于插入、删除操作不频繁的数据集合
+ 数据量不能太小（但是当数据之间的比较操作非常耗时，则也可考虑使用二分查找）
+ 数据量不能过大（因为二分查找是建立在数组之上的，数组需要连续的内存空间）

## 变体：

### 变体一：查找第一个值等于给定值的元素

+ ```java
  public int bsearch(int[] a, int n, int value){
      int low = 0;
      int high = n-1;
      while (low <= high) {
          int mid = low + ((high - low) >> 1);
          if (a[mid] > value){
              high = mid - 1;
          } else if (a[mid] < value) {
              low = mid + 1;
          } else {
              if ((mid == 0)) || (a[mid - 1] != value)) return mid;
              else high = mid - 1;
          }
      }
      return -1;
  }
  ```

+  重点看第 11 行代码。如果 mid 等于 0，那这个元素已经是数组的第一个元素，那它肯定是我们要找的；如果 mid 不等于 0，但 a[mid]的前一个元素 a[mid-1]不等于 value，那也说明 a[mid]就是我们要找的第一个值等于给定值的元素。如果经过检查之后发现 a[mid]前面的一个元素 a[mid-1]也等于 value，那说明此时的 a[mid]肯定不是我们要查找的第一个值等于给定值的元素。那我们就更新 high=mid-1，因为要找的元素肯定出现在[low, mid-1]之间。

### 变体二：查找最后一个值等于给定值的元素

+ ```java
  public int bsearch(int[] a, int n, int value) {
    int low = 0;
    int high = n - 1;
    while (low <= high) {
      int mid =  low + ((high - low) >> 1);
      if (a[mid] > value) {
        high = mid - 1;
      } else if (a[mid] < value) {
        low = mid + 1;
      } else {
        if ((mid == n - 1) || (a[mid + 1] != value)) return mid;
        else low = mid + 1;
      }
    }
    return -1;
  }
  ```

+ 跟变体一很类似

### 变体三：查找第一个大于等于给定值的元素

+ ```java
  public int bsearch(int[] a, int n, int value) {
      int low = 0;
      int high = n - 1;
      while (low <= high) {
          int mid = low + ((high - low) >> 1);
          if (a[mid] >= value) {
              if ((mid == 0) || (a[mid-1] < value)) return mid;
              else high = mid - 1;
          } else {
              low = mid + 1;
          }
      }
      return -1;
  }
  ```

+ 如果 a[mid]小于要查找的值 value，那要查找的值肯定在[mid+1, high]之间，所以，我们更新 low=mid+1。
+ 对于 a[mid]大于等于给定值 value 的情况，我们要先看下这个 a[mid]是不是我们要找的第一个值大于等于给定值的元素。如果 a[mid]前面已经没有元素，或者前面一个元素小于要查找的值 value，那 a[mid]就是我们要找的元素。这段逻辑对应的代码是第 7 行
+ 如果 a[mid-1]也大于等于要查找的值 value，那说明要查找的元素在[low, mid-1]之间，所以，我们将 high 更新为 mid-1

### 变体四：查找最后一个小于等于给定值的元素

+ ```java
  public int bsearch(int[] a, int n, int value) {
      int low = 0;
      int high = n - 1;
      while (low <= high) {
          int mid = low + ((high - low) >> 1);
          if (a[mid] <= value) {
              if ((mid == n -1) || (a[mid + 1] > value)) return mid;
              else low = mid + 1;
          }
          else {
              high = mid - 1;
          }
      }
      return -1;
  }
  ```

+ 跟变体三类似

## 总结：

+ 凡是用二分查找能解决的，绝大部分我们更倾向于使用散列表或二分查找
+ 但二分查找更适合用在”近似”的查找问题上
+ 注意好二分查找代码书写的细节：**终止条件**、**区间上下界更新方法**、**返回值选择**

# 图

+ 相关概念：无向图、有向图、带权图、度、出度、入读、权

## 邻接矩阵存储方法：

+ ![邻接矩阵表示图](D:\note_file\王争数据结构与算法\邻接矩阵表示图.jpg)
+ 优点：查询效率高、方便矩阵运算
+ 缺点：浪费空间

## 邻接表存储方法：

+ ![邻接表表示图](D:\note_file\王争数据结构与算法\邻接表表示图.jpg)
+ 优点：节省空间
+ 缺点：不方便查找，所以针对这个缺点，有了邻接表的改进升级：将链表换成更加高效的数据结构，比如平衡二叉查找树、跳表、散列表

# B+树

+ 常用于数据库索引，数据库索引在性能方面主要从时间和空间两个方面入手，也就是执行效率和存储空间，执行效率方面，我们希望通过索引来提高查询数据的效率，在存储空间方面，我们希望索引不要消耗太多的内存空间
+ 是一种存储在磁盘中的多叉树结构，做到了时间和空间的平衡，既保证了执行效率、又节省了内存

## 特点：

+ 每个节点中子节点的个数不能超过m，也不能小于m/2，这个m是根据页的大小事先计算好的，我们想要每个节点的大小等于一个页的大小，这样读取一个节点的时候只需要一次磁盘IO操作即可
+ 根节点的子节点个数可以不超过m/2，但是至少要有2个指针被使用
+ m叉树只存储索引，不存储真正的数据，有点类似跳表
+ 通过链表将叶子几点串联在一起，方便区间查找
+ 一般情况，根节点会被存储在内存中，其他节点被存储在磁盘中

## B树相对于B+树：

+ B+树中的节点不存储数据，只是索引，但通常B树中的节点是存储数据的，换句话说，从数据库的角度来看，B+树只有叶子节点才存储指向数据库记录或者存储块的指针，但B树的叶子节点和非叶子节点都可以
+ B树中的叶子节点并不需要链表来串联，当然也可以串联
+ B+树中非叶子节点中的索引字段值一定是重复出现在叶子节点中的，但B树索引字段值是没有重复出现的

# 深度和广度优先搜索：

## bfs例代码：

```c++

public void bfs(int s, int t) {
  if (s == t) return;
  boolean[] visited = new boolean[v];
  visited[s]=true;                 // visited数组用来记录某个顶点是不是已经被访问过了
  Queue<Integer> queue = new LinkedList<>();   // queue队列记录的是已经被访问但是相邻节点还没有被访问的顶点，只有把该层
                                                // 的顶点访问完成之后，才开始下一层
  queue.add(s);
  int[] prev = new int[v];    // prev存储的是某个顶点的上一层是谁
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  while (queue.size() != 0) {   
    int w = queue.poll();
   for (int i = 0; i < adj[w].size(); ++i) {     // i要小于邻接表的大小
      int q = adj[w].get(i);
      if (!visited[q]) {
        prev[q] = w;
        if (q == t) {
          print(prev, s, t);
          return;
        }
        visited[q] = true;
        queue.add(q);
      }
    }
  }
}

private void print(int[] prev, int s, int t) { // 递归打印s->t的路径
  if (prev[t] != -1 && t != s) {
    print(prev, s, prev[t]);
  }
  System.out.print(t + " ");
}
```

+ 这里的图的存储结构是邻接表
+ ![bfs](D:\note_file\王争数据结构与算法\bfs.jpg)

## bfs时间空间复杂度：

+ 时间复杂度O(E)、空间复杂度O(V)。V表示顶点的个数，E表示边的个数

## dfs例代码：

```c++
boolean found = false; // 全局变量或者类成员变量

public void dfs(int s, int t) {
  found = false;
  boolean[] visited = new boolean[v];
  int[] prev = new int[v];
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  recurDfs(s, t, visited, prev);
  print(prev, s, t);
}

private void recurDfs(int w, int t, boolean[] visited, int[] prev) {
  if (found == true) return;
  visited[w] = true;
  if (w == t) {
    found = true;
    return;
  }
  for (int i = 0; i < adj[w].size(); ++i) {
    int q = adj[w].get(i);
    if (!visited[q]) {
      prev[q] = w;
      recurDfs(q, t, visited, prev);
    }
  }
}
```

+ ![dfs](D:\note_file\王争数据结构与算法\dfs.jpg)

## dfs时间空间复杂度：

+ 时间复杂度O(E)，空间复杂度O(V)。其中E表示边的个数，V表示顶点数

# 字符串匹配

## BF算法：

+ ![BF字符串匹配](D:\note_file\王争数据结构与算法\BF字符串匹配.jpg)

+ **主串**和**模式串**：如果在字符串A中查找字符串B，那字符串A就是主串，字符串B就是模式串

+ **时间复杂度**：理论上很高，为O(n*m)，但实际开发中没有那么大，反而效率用的很多

## RK算法：

+ 是通过引入哈希算法来降低时间复杂度。
+ 对n-m+1个字串求哈希值，然后逐个与模式串的哈希值比较大小
+ 通常使用的是，如果字符串中的字符集有K个字符，可以考虑使用K进制数来进行哈希设计
+ 如果哈希算法设计不合理，会出现哈希冲突，应对哈希冲突可以通过比较真的字符串来解决
+ **时间复杂度**为O(n)
+ 如果哈希冲突太高，RK算法则会退化成时间复杂度为O(n*m)

## BM算法：

### 思想本质：

+ 本质上是在寻找一种规律，借助这种规律，在模式串与主串匹配的过程中，能够跳过一些肯定不会匹配的情况，将模式串往后多滑动几位

### BM算法原理：

+ 包括**坏字符规则**和**好后缀规则**
+ `https://time.geekbang.org/column/article/71525`

### 代码实现：

#### 散列表生成代码：

```c++

private static final int SIZE = 256; // 全局变量或成员变量
private void generateBC(char[] b, int m, int[] bc) {
  for (int i = 0; i < SIZE; ++i) {
    bc[i] = -1; // 初始化bc
  }
  for (int i = 0; i < m; ++i) {
    int ascii = (int)b[i]; // 计算b[i]的ASCII值
    bc[ascii] = i;
  }
}
```

#### BM算法代码大框架（只考虑坏字符情况）：

```c++

public int bm(char[] a, int n, char[] b, int m) {
  int[] bc = new int[SIZE]; // 记录模式串中每个字符最后出现的位置
  generateBC(b, m, bc); // 构建坏字符哈希表
  int i = 0; // i表示主串与模式串对齐的第一个字符
  while (i <= n - m) {
    int j;
    for (j = m - 1; j >= 0; --j) { // 模式串从后往前匹配
      if (a[i+j] != b[j]) break; // 坏字符对应模式串中的下标是j
    }
    if (j < 0) {
      return i; // 匹配成功，返回主串与模式串第一个匹配的字符的位置
    }
    // 这里等同于将模式串往后滑动j-bc[(int)a[i+j]]位
    i = i + (j - bc[(int)a[i+j]]); 
  }
  return -1;
}
```

+ 不仅要在模式串中，查找跟好后缀匹配的另一个子串，还要在好后缀的后缀子串中，查找最长的能跟模式串前缀子串匹配的后缀子串

#### suffix数组和prefix数组的代码：

```c++

// b表示模式串，m表示长度，suffix，prefix数组事先申请好了
private void generateGS(char[] b, int m, int[] suffix, boolean[] prefix) {
  for (int i = 0; i < m; ++i) { // 初始化
    suffix[i] = -1;
    prefix[i] = false;
  }
  for (int i = 0; i < m - 1; ++i) { // b[0, i]
    int j = i;
    int k = 0; // 公共后缀子串长度
    while (j >= 0 && b[j] == b[m-1-k]) { // 与b[0, m-1]求公共后缀子串
      --j;
      ++k;
      suffix[k] = j+1; //j+1表示公共后缀子串在b[0, i]中的起始下标
    }
    if (j == -1) prefix[k] = true; //如果公共后缀子串也是模式串的前缀子串
  }
}
```

#### BM完整代码：

```c++

// a,b表示主串和模式串；n，m表示主串和模式串的长度。
public int bm(char[] a, int n, char[] b, int m) {
  int[] bc = new int[SIZE]; // 记录模式串中每个字符最后出现的位置
  generateBC(b, m, bc); // 构建坏字符哈希表
  int[] suffix = new int[m];
  boolean[] prefix = new boolean[m];
  generateGS(b, m, suffix, prefix);
  int i = 0; // j表示主串与模式串匹配的第一个字符
  while (i <= n - m) {
    int j;
    for (j = m - 1; j >= 0; --j) { // 模式串从后往前匹配
      if (a[i+j] != b[j]) break; // 坏字符对应模式串中的下标是j
    }
    if (j < 0) {
      return i; // 匹配成功，返回主串与模式串第一个匹配的字符的位置
    }
    int x = j - bc[(int)a[i+j]];
    int y = 0;
    if (j < m-1) { // 如果有好后缀的话
      y = moveByGS(j, m, suffix, prefix);
    }
    i = i + Math.max(x, y);
  }
  return -1;
}

// j表示坏字符对应的模式串中的字符下标; m表示模式串长度
private int moveByGS(int j, int m, int[] suffix, boolean[] prefix) {
  int k = m - 1 - j; // 好后缀长度
  if (suffix[k] != -1) return j - suffix[k] +1;
  for (int r = j+2; r <= m-1; ++r) {
    if (prefix[m-r] == true) {
      return r;
    }
  }
  return m;
}
```

### KMP算法：

#### 思想本质：

+ KMP算法也是在寻找一种规律：在模式串和主串匹配的过程中，当遇到坏字符后，对于已经比对过的好前缀，能否找到一种规律，将模式串一次性滑动很多位

#### KMP框架代码：

```c++

// a, b分别是主串和模式串；n, m分别是主串和模式串的长度。
public static int kmp(char[] a, int n, char[] b, int m) {
  int[] next = getNexts(b, m);
  int j = 0;
  for (int i = 0; i < n; ++i) {
    while (j > 0 && a[i] != b[j]) { // 一直找到a[i]和b[j]
      j = next[j - 1] + 1;
    }
    if (a[i] == b[j]) {
      ++j;
    }
    if (j == m) { // 找到匹配模式串的了
      return i - m + 1;
    }
  }
  return -1;
}
```

#### 失效函数代码（next数组）：

```c++

// b表示模式串，m表示模式串的长度
private static int[] getNexts(char[] b, int m) {
  int[] next = new int[m];
  next[0] = -1;
  int k = -1;
  for (int i = 1; i < m; ++i) {
    while (k != -1 && b[k + 1] != b[i]) {
      k = next[k];
    }
    if (b[k + 1] == b[i]) {
      ++k;
    }
    next[i] = k;
  }
  return next;
}
```

#### 整体代码的python实现

```python

```



#### 复杂度：

+ 时间复杂度：O(m+n)，n是主串长度，m是模式串长度
+ 空间复杂度：O(m)，m是模式串长度

# 贪心算法

## 解决问题的步骤：

一、当看到这类问题时，可以考虑是否使用贪心算法：针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大

二、我们尝试看下这个问题能否可以用贪心算法解决：每次选择某一种情况时，在对限制值同等贡献量的情况下，对期望值贡献最大的数据

三、举几个例子验证一下

+ 实际上，用贪心算法解决问题的思路，并不总能给出最优解

# 分治算法

## 核心思想：

+ **分而治之**，将原问题划分成n个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解

## 分治算法的递归实现：

+ 分治算法一般都比较适合用递归来实现。分治算法的递归实现中，每一层递归都会涉及三个操作
  + 分解：将原问题分解成一系列子问题
  + 解决：递归求解各个子问题，若子问题足够小，则直接求解
  + 合并：将子问题的结果合并成原问题

## 分治算法能解决问题所满足的条件：

+ 原问题与分解成的小问题具有相同的模式
+ 原问题分解成的子问题可以独立求解，子问题之间没有相关性，这一点是分治算法跟动态规划的明显区别，等我们讲到动态规划的时候，会详细对比这两种算法
+ 具有分解终止条件，也就是说，当问题足够小时，可以直接求解
+ 可以将子问题合并成原问题，而这个合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果了

## 利用分治思想+归并排序求逆序对的个数：

+ ```java
  private int num = 0;
  
  public int count(int[] a, int n) {
      num = 0;
      mergeSortCounting(a, 0, n-1);
      return num;
  }
  
  private void mergeSortCounting(int[] a, int p, int r) {
      if (p >= r) return;
      if q = (p + r)/2;
      mergeSortCounting(a, p, q);
      mergeSortCounting(a, q+1, r);
      merge(a, p, q, r);
  }
  
  private void merge(int[] a, int p, int q, int r) {
      int i = p, j = q+1, k = 0;
      int[] tmp = new int[r-p+1];
      while (i<=q && j<=r) {
          if (a[i] <= a[j]) {
              tmp[k++] = a[i++];
          } else {
              num += (q-i+1);
              tmp[k++] = a[j++];
          }
      }
      while (i <= q) {
          tmp[k++] = a[i++];
      }
      while (j <= r) {
          tmp[k++] = a[j++];
      }
      for (i = p; i <= r; ++i) {
          a[i] = tmp[i-p];
      }
  }
  ```

# 回溯算法

## 什么是回溯：

+ 回溯算法很多时候都应用在“搜索”这类问题上。不过这里说的搜索，是指在一组可能的解中，搜索满足期望的解

## 基本思想：

+ 回溯法的整体思路是：搜索每一条路，每次回溯是对具体的一条路径而言的。对当前搜索路径下的的未探索区域进行搜索，则可能有两种情况：

  1. 当前未搜索区域满足结束条件，则保存当前路径并退出当前搜索；
  2. 当前未搜索区域需要继续搜索，则遍历当前所有可能的选择：如果该选择符合要求，则把当前选择加入当前的搜索路径中，并继续搜索新的未探索区域。

### 正规模板代码：

```python
res = []
path = []

def backtrack(未探索区域, res, path):
    if path 满足条件:
        res.add(path) # 深度拷贝，因为每一层的path是一样的
        # return  # 如果不用继续搜索需要 return
    for 选择 in 未探索区域当前可能的选择:
        if 当前选择符合要求:
            path.add(当前选择)
            backtrack(新的未探索区域, res, path)
            path.pop()
```

**注意**：

+ backtrack 的含义是：未探索区域中到达结束条件的所有可能路径，path 变量是保存的是一条路径，res 变量保存的是所有搜索到的路径。所以当「未探索区域满足结束条件」时，需要把 path 放到结果 res 中。
+ path.pop() 是啥意思呢？它是编程实现上的一个要求，即我们从始至终只用了一个变量 path，所以当对 path 增加一个选择并 backtrack 之后，需要清除当前的选择，防止影响其他路径的搜索。

### 简化模板代码：

+ 就是在正规模板代码的基础上，传入path的时候，传入的是一个新数组`path + [s[:i]]`，这样每一层使用的都是不同的path，所以不再需要pop操作



## 典型例题：

### 八皇后：

+ java实现

+ ```java
  int[] result = new int[8];//全局或成员变量,下标表示行,值表示queen存储在哪一列
  public void cal8queens(int row) { // 调用方式：cal8queens(0);
    if (row == 8) { // 8个棋子都放置好了，打印结果
      printQueens(result);
      return; // 8行棋子都放好了，已经没法再往下递归了，所以就return
    }
    for (int column = 0; column < 8; ++column) { // 每一行都有8中放法
      if (isOk(row, column)) { // 有些放法不满足要求
        result[row] = column; // 第row行的棋子放到了column列
        cal8queens(row+1); // 考察下一行
      }
    }
  }
  
  private boolean isOk(int row, int column) {//判断row行column列放置是否合适
    int leftup = column - 1, rightup = column + 1;
    for (int i = row-1; i >= 0; --i) { // 逐行往上考察每一行
      if (result[i] == column) return false; // 第i行的column列有棋子吗？
      if (leftup >= 0) { // 考察左上对角线：第i行leftup列有棋子吗？
        if (result[i] == leftup) return false;
      }
      if (rightup < 8) { // 考察右上对角线：第i行rightup列有棋子吗？
        if (result[i] == rightup) return false;
      }
      --leftup; ++rightup;
    }
    return true;
  }
  
  private void printQueens(int[] result) { // 打印出一个二维矩阵
    for (int row = 0; row < 8; ++row) {
      for (int column = 0; column < 8; ++column) {
        if (result[row] == column) System.out.print("Q ");
        else System.out.print("* ");
      }
      System.out.println();
    }
    System.out.println();
  }
  ```

+ python实现

+ ```python
  result = [0]*8
  def cal8queens(row: int):
      if row == 8:
          printQueen(result)
          return
      for col in range(8):
          if isOk(row, col):
              result[row] = col
              cal8queens(row+1)
  
  def isOk(row, col):
      leftup = col - 1
      rightup = col + 1
      for x in range(row-1, -1, -1):
          if result[x] == col:
              return False
          if leftup >= 0 and result[x] == leftup:
              return False
          if rightup < 8 and result[x] == rightup:
              return False
          leftup -= 1
          rightup += 1
      return True
  
  def printQueen(result):
      for row in range(8):
          for col in range(8):
              if result[row] == col:
                  print('Q', end='')
              else:
                  print('*', end='')
          print()
      print()  
  cal8queens(0)
  ```

### 0-1背包问题：

+ java实现

+ ```java
  public int maxW = Integer.MIN_VALUE; //存储背包中物品总重量的最大值
  // cw表示当前已经装进去的物品的重量和；i表示考察到哪个物品了；
  // w背包重量；items表示每个物品的重量；n表示物品个数
  // 假设背包可承受重量100，物品个数10，物品重量存储在数组a中，那可以这样调用函数：
  // f(0, 0, a, 10, 100)
  public void f(int i, int cw, int[] items, int n, int w) {
    if (cw == w || i == n) { // cw==w表示装满了;i==n表示已经考察完所有的物品
      if (cw > maxW) maxW = cw;
      return;
    }
    f(i+1, cw, items, n, w);
    if (cw + items[i] <= w) {// 已经超过可以背包承受的重量的时候，就不要再装了
      f(i+1,cw + items[i], items, n, w);
    }
  }
  ```

+ python实现

+ ```python
  def f(i, cw, items, n, w):
      if cw == w or i == n:
          if cw > maxW:
              maxW = cw
          return
      f(i+1, cw, items, n, w) # 表示不选这一个
      if cw + items[i] <= w:  # 进行剪枝操作，当选中这个物品就大于了总重量后，就不用再装了
          f(i+1, cw + items[i], items, n, w)  # 表示选择这一个    
  
  f(0, 0, a, 10, 100)
  ```

+ 采用备忘录的形式（记忆型递归）

+ ```java
  private int maxW = Integer.MIN_VALUE; // 结果放到maxW中
  private int[] weight = {2，2，4，6，3};  // 物品重量
  private int n = 5; // 物品个数
  private int w = 9; // 背包承受的最大重量
  private boolean[][] mem = new boolean[5][10]; // 备忘录，默认值false
  public void f(int i, int cw) { // 调用f(0, 0)
    if (cw == w || i == n) { // cw==w表示装满了，i==n表示物品都考察完了
      if (cw > maxW) maxW = cw;
      return;
    }
    if (mem[i][cw]) return; // 重复状态
    mem[i][cw] = true; // 记录(i, cw)这个状态
    f(i+1, cw); // 选择不装第i个物品
    if (cw + weight[i] <= w) {
      f(i+1,cw + weight[i]); // 选择装第i个物品
    }
  }
  ```
  
+ 把已经计算好的f(i,cw)记录下来，当再次计算到重复的f(i, cw)的时候，直接从备忘录中取出来用，不需要再递归计算了，这样时间复杂度的优化是非常好的，甚至跟动态规划的执行效率基本没有差别了

# 动态规划

+ 动态规划比较适合用来求解最优问题，比如最大值、最小值

## 求解0-1背包问题：

### 不附带价值，且省空间的一种做法：

```java
public static int knapsack2(int[] items, int n, int w) {
  boolean[] states = new boolean[w+1]; // 默认值false
  states[0] = true;  // 第一行的数据要特殊处理，可以利用哨兵优化
  if (items[0] <= w) {
    states[items[0]] = true;  // 第零个物品选了的对应的状态处设置为true
  }
  for (int i = 1; i < n; ++i) { // 动态规划状态转移
    for (int j = w-items[i]; j >= 0; --j) {//把第i个物品放入背包
      if (states[j]==true) states[j+items[i]] = true;
    }
  }
  for (int i = w; i >= 0; --i) { // 输出结果
    if (states[i] == true) return i;
  }
  return 0;
}

```

### 不附带价值，不省空间的一种做法：

```java

weight:物品重量，n:物品个数，w:背包可承载重量
public int knapsack(int[] weight, int n, int w) {
  boolean[][] states = new boolean[n][w+1]; // 默认值false
  states[0][0] = true; // 第一行的数据要特殊处理，可以利用哨兵优化，第一个物品不选
  if (weight[0] <= w) {  // 第一个物品选
    states[0][weight[0]] = true;
  }
  for (int i = 1; i < n; ++i) { // 动态规划状态转移
    for (int j = 0; j <= w; ++j) {// 不把第i个物品放入背包
      if (states[i-1][j] == true) states[i][j] = states[i-1][j];
    }
    for (int j = 0; j <= w-weight[i]; ++j) {//把第i个物品放入背包
      if (states[i-1][j]==true) states[i][j+weight[i]] = true;
    }
  }
  for (int i = w; i >= 0; --i) { // 输出结果
    if (states[n-1][i] == true) return i;
  }
  return 0;
}
```

### 附带价值之后：

```java
public static int knapsack3(int[] weight, int[] value, int n, int w) {
    int[][] states = new int[n][w+1];
    for (int i = 0;i < n; ++i) {  // 初始化数组
        for (int j = 0; j < w+1; ++j) {
            states[i][j] = -1;
        }
    }
    states[0][0] = 0;
    if (weight[0] <= w) {  // 对第一个物品特殊处理
        states[0][weight[0]] = value[0];
    }
    for (int i = 1; i < n; ++i) {      // 动态规划状态转移
        for (int j = 0; j <= w; ++j) {    // 不选第i个物品
            if (states[i-1][j] >= 0) states[i][j] = states[i-1][j];
        }
        for (int j = 0; j <= w - weight[i]; ++j) {   // 选第i个物品
            if (states[i-1][j] >= 0) {
                int v = states[i-1][j] + value[i];
                if (v > states[i][j+weight[i]]) {
                    states[i][j+weight[i]] = v;
                }
            }
        }
    }
    // 找最大值
    int maxvalue = -1;
    for (j = 0; j <= w; ++j) {
        if (states[n-1][j] > maxvalue) maxvalue = states[n-1][j];
    }
    return maxvalue;
}
```

## 动态规划理论：

## 什么样的问题适合用动态规划来解决：

### 一个模型：

+ 也叫**多阶段决策最优解模型**
+ 动态规划一般用来解决最优问题。解决问题的过程，需要经历多个决策阶段，每个决策阶段都对应着一组状态。然后我们寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。

### 三个特征：

+ **最优子结构**：问题的最优解包含子问题的最优解。反过来说就是，我们可以通过子问题的最优解，推导出问题的最优解。如果我们把最优子结构，对应到我们前面定义的动态规划问题模型上，那我们也可以理解为，后面阶段的状态可以通过前面阶段的状态推导出来。
+ **无后效性**：无后效性有两层含义，第一层含义是，在推导后面阶段的状态的时候，我们只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。第二层含义是，某阶段状态一旦确定，就不受之后阶段的决策影响。无后效性是一个非常“宽松”的要求。只要满足前面提到的动态规划问题模型，其实基本上都会满足无后效性。
+ **重复子问题**：不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。

## 如何解决动态规划：

### 状态转移表法：

+ 我们先画出一个状态表。状态表一般都是二维的，所以你可以把它想象成二维数组。其中，每个状态包含三个变量，行、列、数组值。我们根据决策的先后过程，从前往后，根据递推关系，分阶段填充状态表中的每个状态。最后，我们将这个递推填表的过程，翻译成代码，就是动态规划代码了。
+ **大致思路：**回溯算法实现 - 定义状态 - 画递归树 - 找重复子问题 - 画状态转移表 - 根据递推关系填表 - 将填表过程翻译成代码

### 状态转移方程法：

+ 状态转移方程法有点类似递归的解题思路。我们需要分析，某个问题如何通过子问题来递归求解，也就是所谓的最优子结构。根据最优子结构，写出递归公式，也就是所谓的状态转移方程。有了状态转移方程，代码实现就非常简单了。一般情况下，我们有两种代码实现方法，一种是**递归加“备忘录”**，另一种是**迭代递推**。
+ **大致思路：**找最优子结构 - 写状态转移方程 - 将状态转移方程翻译成代码

### 动态规划相比回溯，是解决了重复计算的问题

### 硬币找零问题：

+ 硬币找零问题，我们在贪心算法那一节中讲过一次。我们今天来看一个新的硬币找零问题。假设我们有几种不同币值的硬币 v1，v2，……，vn（单位是元）。如果我们要支付 w 元，求最少需要多少个硬币。比如，我们有 3 种不同的硬币，1 元、3 元、5 元，我们要支付 9 元，最少需要 3 个硬币（3 个 3 元的硬币）

+ 直接递归（回溯的算法思想）：

  ```python
  coin = 0
  def minCoin(money):
      global coin
      if money == 1:return 1
      if money == 2:return 2
      if money == 3:return 1
      if money == 4:return 2
      if money == 5:return 1
      if money <= 0:return 0
      
      coin = 1 + min(minCoin(money - 1), minCoin(money - 3), minCoin(money - 5))
      return coin
  print(minCoin(10))
  ```

+ 记忆型递归（注意跟直接递归相比，只是加了一个记忆）：

  ```python
  map = {} # 初始化一个字典，记忆已经算出来的剩多少钱是需要的最少硬币数
  coin = 0
  def minCoin(money):
      global coin
      # 查表
      if money in map:
          return map[money]
      if money == 1:return 1
      if money == 2:return 2
      if money == 3:return 1
      if money == 4:return 2
      if money == 5:return 1
      if money <= 0:return 0
      
      coin = 1 + min(minCoin(money - 1), minCoin(money - 3), minCoin(money - 5)) 
      map[money] = coin
      
      return coin
  print(minCoin(10))
  ```

+ 动态规划方法（这里用的是填表法）：

  ```python
  # 动态规划方程：coin = 1 + min(minCoin(money - 1), minCoin(money - 3), minCoin(money - 5))
  s = [] # dp数组
  s[0], s[1], s[3], s[4], s[5] = 1, 2, 1, 2, 1 # 初始化dp
  def minCoin(money):
      for i in range(6, money + 1):
          s[i] = 1 + min(s[i-1], s[i-3], s[i-5])
      return s[money]
  print(minCoin(10))
  ```

## 动态规划实战：

+ **多练**

# Trie树（字典树）

## 本质：

+ 利用字符串之间的公共前缀，将重复的前缀合并在一起
+ 是一种树形数据结构，用于高效地存储和检索字符串数据集中的键

## 存储和查询的代码：

+ ```java
  public class Trie {
    private TrieNode root = new TrieNode('/'); // 存储无意义字符
  
    // 往Trie树中插入一个字符串
    public void insert(char[] text) {
      TrieNode p = root;
      for (int i = 0; i < text.length; ++i) {
        int index = text[i] - 'a';
        if (p.children[index] == null) {
          TrieNode newNode = new TrieNode(text[i]);
          p.children[index] = newNode;
        }
        p = p.children[index];
      }
      p.isEndingChar = true;
    }
  
    // 在Trie树中查找一个字符串
    public boolean find(char[] pattern) {
      TrieNode p = root;
      for (int i = 0; i < pattern.length; ++i) {
        int index = pattern[i] - 'a';
        if (p.children[index] == null) {
          return false; // 不存在pattern
        }
        p = p.children[index];
      }
      if (p.isEndingChar == false) return false; // 不能完全匹配，只是前缀
      else return true; // 找到pattern
    }
  
    public class TrieNode {
      public char data;
      public TrieNode[] children = new TrieNode[26];
      public boolean isEndingChar = false;
      public TrieNode(char data) {
        this.data = data;
      }
    }
  }
  ```

## 查询的时间复杂度：

+ O(k)，k表示要查找的字符串的长度

## 优化：

+ 缩点优化：对于只有一个子节点的节点，而且此节点不是一个串的结束节点，可以将此节点与子节点合并

## 应用：

+ Trie树比较耗费内存
+ 其优势不在于用来做动态集合数据查找，因为这个工作通常用更加适合的散列表和红黑树来代替，Trie树最有优势的是查找前缀匹配的字符串

## 实现Trie（leetcode.208）：

### 每个节点的字段：

+ 指向子节点的指针数组children，长度为字符集的大小
+ 布尔字段isEnd，表示该节点是否为字符串的结尾

### 插入字符串：

+ 从字典树的根开始，插入字符串，对于当前字符对应的子节点，有两种情况：
  + 子节点存在，沿着指针移动到子节点，继续处理下一个字符
  + 子节点不存在，创建一个新的子节点，记录在children数组的对应位置上，之后沿着指针移动到子节点，继续搜索下一个字符

+ 重复以上步骤，直到处理字符串的最后一个字符，然后将当前节点标记为字符串的结尾

### 查找前缀：

+ 从字典树的根开始，查找前缀，对于当前字符对应的子节点，有两种情况：
  + 子节点存在，沿着指针移动到子节点，继续搜索下一个字符
  + 子节点不存在，说明字典树中不含该前缀，返回空
+ 重复以上步骤，直到返回空指针或搜索完前缀的最后一个字符
+ 若搜索到了前缀的末尾，就说明字符串中存在该前缀，此外，若前缀末尾对应节点的isEnd为真，则说明字典树中存在该字符串

### python实现

+ ```python
  class Trie:
      def __init__(self):
          self.children = [None] * 26
          self.isEnd = False
          
      def insert(self, word: str) -> None:
          node = self
          for ch in word:
              ch = ord(ch) - ord("a")
              if not node.children[ch]:
                  node.children[ch] = Trie()
              node = node.children[ch]
          node.isEnd = True
          
      def Prefix(self, prefix: str) -> "Trie":
          node = self
          for ch in prefix:
              ch = ord(ch) - ord("a")
              if not node.children[ch]:
                  return None
              node = node.children[ch]
          return node
          
      def findWord(self, word: str) -> bool:
          node = self.Prefix(word)
          return node is not None and node.isEnd
      
      def findPrefix(self, prefix: str) -> bool:
          node = self.Prefix(prefix)
          return node is not None
  ```
  
  

# AC自动机

## 本质：

+ AC自动机实际上就是在Trie树之上，加了类似KMP的next数组，只不过此处的next数组是构建在树上罢了
+ AC 自动机是基于 Trie 树的一种改进算法，它跟 Trie 树的关系，就像单模式串中，KMP 算法与 BF 算法的关系一样。KMP 算法中有一个非常关键的 next 数组，类比到 AC 自动机中就是失败指针

## AC自动机算法包含两个部分：

+ 第一部分是将多个模式串构建成AC自动机
  + 将模式串构建成Trie树
  + 在Trie树上构建失败指针（类似KMP算法中的next数组）
+ 第二部分是在AC自动机中匹配主串

# 最短路径

## 先将图抽象为一个有向有权图：

+ ```java
  public class Graph { // 有向有权图的邻接表表示
    private LinkedList<Edge> adj[]; // 邻接表
    private int v; // 顶点个数
  
    public Graph(int v) {
      this.v = v;
      this.adj = new LinkedList[v];
      for (int i = 0; i < v; ++i) {
        this.adj[i] = new LinkedList<>();
      }
    }
  
    public void addEdge(int s, int t, int w) { // 添加一条边
      this.adj[s].add(new Edge(s, t, w));
    }
  
    private class Edge {
      public int sid; // 边的起始顶点编号
      public int tid; // 边的终止顶点编号
      public int w; // 权重
      public Edge(int sid, int tid, int w) {
        this.sid = sid;
        this.tid = tid;
        this.w = w;
      }
    }
    // 下面这个类是为了dijkstra实现用的
    private class Vertex {
      public int id; // 顶点编号ID
      public int dist; // 从起始顶点到这个顶点的距离
      public Vertex(int id, int dist) {
        this.id = id;
        this.dist = dist;
      }
    }
  }
  ```

## Dijkstra算法：

+ 单源最短路径算法（一个顶点到一个顶点）

+ 代码

  ```java
  // 因为Java提供的优先级队列，没有暴露更新数据的接口，所以我们需要重新实现一个
  private class PriorityQueue { // 根据vertex.dist构建小顶堆
    private Vertex[] nodes;
    private int count;
    public PriorityQueue(int v) {
      this.nodes = new Vertex[v+1];
      this.count = v;
    }
    public Vertex poll() { // TODO: 留给读者实现... }
    public void add(Vertex vertex) { // TODO: 留给读者实现...}
    // 更新结点的值，并且从下往上堆化，重新符合堆的定义。时间复杂度O(logn)。
    public void update(Vertex vertex) { // TODO: 留给读者实现...} 
    public boolean isEmpty() { // TODO: 留给读者实现...}
  }
  
  public void dijkstra(int s, int t) { // 从顶点s到顶点t的最短路径
    int[] predecessor = new int[this.v]; // 用来还原最短路径
    Vertex[] vertexes = new Vertex[this.v];
    for (int i = 0; i < this.v; ++i) {
      vertexes[i] = new Vertex(i, Integer.MAX_VALUE);
    }
    PriorityQueue queue = new PriorityQueue(this.v);// 小顶堆
    boolean[] inqueue = new boolean[this.v]; // 标记是否进入过队列
    vertexes[s].dist = 0;
    queue.add(vertexes[s]);
    inqueue[s] = true;
    while (!queue.isEmpty()) {
      Vertex minVertex= queue.poll(); // 取堆顶元素并删除
      if (minVertex.id == t) break; // 最短路径产生了
      for (int i = 0; i < adj[minVertex.id].size(); ++i) {
        Edge e = adj[minVertex.id].get(i); // 取出一条minVetex相连的边
        Vertex nextVertex = vertexes[e.tid]; // minVertex-->nextVertex
        if (minVertex.dist + e.w < nextVertex.dist) { // 更新next的dist
          nextVertex.dist = minVertex.dist + e.w;
          predecessor[nextVertex.id] = minVertex.id;
          if (inqueue[nextVertex.id] == true) {
            queue.update(nextVertex); // 更新队列中的dist值
          } else {
            queue.add(nextVertex);
            inqueue[nextVertex.id] = true;
          }
        }
      }
    }
    // 输出最短路径
    System.out.print(s);
    print(s, t, predecessor);
  }
  
  private void print(int s, int t, int[] predecessor) {
    if (s == t) return;
    print(s, predecessor[t], predecessor);
    System.out.print("->" + t);
  }
  ```

+ **逻辑：**我们用 vertexes 数组，记录从起始顶点到每个顶点的距离（dist）。起初，我们把所有顶点的 dist 都初始化为无穷大（也就是代码中的 Integer.MAX_VALUE）。我们把起始顶点的 dist 值初始化为 0，然后将其放到优先级队列中。

  ​	我们从优先级队列中取出 dist 最小的顶点 minVertex，然后考察这个顶点可达的所有顶点（代码中的 nextVertex）。如果 minVertex 的 dist 值加上 minVertex 与 nextVertex 之间边的权重 w 小于 nextVertex 当前的 dist 值，也就是说，存在另一条更短的路径，它经过 minVertex 到达 nextVertex。那我们就把 nextVertex 的 dist 更新为 minVertex 的 dist 值加上 w。然后，我们把 nextVertex 加入到优先级队列中。重复这个过程，直到找到终止顶点 t 或者队列为空。

+ **时间复杂度：**O(E*logV)，E表示所有边的个数，V表示顶点的个数

### 步骤：

+ 将图中所有的顶点分为两部分，已知最短路径的顶点集合P和未知的顶点集合Q。初始时，P中只有一个源顶点1号。用book数组来标记顶点是否在P中，1表示在P中，0表示在Q中，dis数组来记录最短路径，数组下标来表示顶点的下标，设置源点1到其他顶点的路径值放置到dis中
+ 在dis中找到源点s到其他顶点的最短路径u顶点，将其加入到P集合，并考察以u顶点为起点的出边，然后对dis进行更新。更新：如果存在一条从u到v的边，那么可以拓展一条从s到u再到v的边，路径长度位dis[u]+edge[u][v\]，如果这个值比目前的值dis[v\]小，就进行更新
+ 重复上一步，直到Q为空，即book都被标记，此时dis数组中就是源点到各个顶点的最短路径

### python代码实现

```python
Inf = float('inf')

# 例子
##Adjacent = [[0, Inf, Inf, Inf, Inf, Inf, Inf],
##            [Inf, 0, 1, 12, Inf, Inf, Inf],
##            [Inf, Inf, 0, 9, 3, Inf, Inf],
##            [Inf, Inf, Inf, 0, Inf, 5, Inf],
##            [Inf, Inf, Inf, 4, 0, 13, 15],
##            [Inf, Inf, Inf, Inf, Inf, 0, 4],
##            [Inf, Inf, Inf, Inf, Inf, Inf, 0]]
##src, dst, n = 1, 6, 6  # 起点编号、终点编号、结点个数

n, m = map(int, input().split(" "))  # n为节点数，m为边数
Adjacent = [[Inf]*(n+1) for _ in range(n+1)]
for i in range(n+1):
    Adjacent[i][i] = 0
for _ in range(m):
    x, y, z = map(int, input().split(" "))
    Adjacent[x][y] = z
src = 1  # 源节点（最后返回的列表存储的就是该源节点到各个节点的距离）

def dijstra(adj, src, n):
    dist = [Inf]*(n+1)  # 存储src到各个顶点的最短距离
    dist[src] = 0    # 初始化，src到src的距离为0
    book = [0]*(n+1)  # 记录顶点是否已经确定，0表示未确定，1表示已经确定
    u = src   # 从源点开始
    for i in range(1, n+1):   # 遍历
        if u == None:
            break
        book[u] = 1   # 将u进行标记为已经确定
        # next_u是记录下一个u,在更新u的临接节点的时候动态更新，因为next_u是距离源点src最近的那个点，minVal为对应距离
        next_u, minVal = None, Inf
        # 一开始要先将next_u和minVal更新为当前dist中minVal最小的那一个节点
        # 以防后面出现：无法更新到next_u，即使并没有更新完所有的节点，
        # next_u却也为None的情况
        for i in range(1, n+1):
            if book[i] == 0:
                if dist[i] < minVal:
                    next_u = i
                    minVal = dist[i]
        for v in range(1, n+1):  # 遍历所有节点
            w = adj[u][v]   # u到v的距离
            if w == Inf:   # 如果距离为Inf，说明没有边连接u和v
                continue
            # 如果v点还未确定且当前从源点到u的距离加上u到v距离比从源点直接到v的距离小则进行更新
            if book[v] == 0 and dist[u] + w < dist[v]:  
                dist[v] = dist[u] + w
                if dist[v] < minVal:   # 更新next_u和minVal
                    next_u, minVal = v, dist[v]
        u = next_u
    print(dist[1:])
    return dist[1:]

dijstra(Adjacent, src, n)  # 参数：邻接矩阵、源节点、节点个数
```



## 其他最短路径算法：

+ Bellford算法、Floyd算法、A*启发式搜索算法







